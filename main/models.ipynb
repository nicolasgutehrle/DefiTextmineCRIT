{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF Classifier\n",
    "\n",
    "To extract and extract Extended NER candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "import joblib \n",
    "\n",
    "from typing import List\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(data:pd.DataFrame) -> None:\n",
    "    \"\"\"Simple function to clean Tokens\n",
    "\n",
    "    :param data: DataFrame containing the data\n",
    "    :type data: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    data['Token'] = data['Token'].str.replace('\"', '')\n",
    "\n",
    "def getLinguisticFeatures(list_tokens:List[str], nlp) -> dict:\n",
    "    doc = Doc(nlp.vocab, words=list_tokens)\n",
    "    for pipe in filter(None, nlp.pipeline):\n",
    "        pipe[1](doc)\n",
    "    return {\n",
    "        \"POS\": [x.pos_ for x in doc],\n",
    "        'DEP': [x.dep_ for x in doc]\n",
    "    }\n",
    "\n",
    "def getStringShape(word:str) -> str:\n",
    "    \"\"\"Get the shape of the string as either X for capital letters, d for digits, . for punctuations and x for normal letters\n",
    "\n",
    "    :param string: String to get the shape of\n",
    "    :type string: str\n",
    "    :return: Shape of the string (e.g. Port: Xxxx)\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    shape = []\n",
    "    for x in word:\n",
    "        if x.isupper():\n",
    "            shape.append('X')\n",
    "        elif x.isdigit():\n",
    "            shape.append('d')\n",
    "        elif x in string.punctuation:\n",
    "            shape.append('.')\n",
    "        else:\n",
    "            shape.append('x')\n",
    "    return ''.join(shape)\n",
    "    \n",
    "def extractFeatures(data:pd.DataFrame, nlp)->None:\n",
    "    \"\"\"\n",
    "    Extract features from Token column of the dataframe\n",
    "\n",
    "    :param data: DataFrame contianing the data\n",
    "    :type data: pd.DataFrame\n",
    "    \"\"\"\n",
    "    data['lower'] = [x.lower() for x in data['Token']]\n",
    "    data['isdigit'] = [x.isdigit() for x in data['Token']]\n",
    "    data['isupper'] = [x.isupper() for x in data['Token']]\n",
    "    data['ispunct'] = [x in string.punctuation for x in data['Token']]\n",
    "    data['isstop'] = [x in nlp.Defaults.stop_words for x in data['Token']]\n",
    "    data['len'] = [len(x) for x in data['Token']]\n",
    "    data['shape'] = [getStringShape(x) for x in data['Token']]\n",
    "    \n",
    "    linguistic_features = getLinguisticFeatures(data['Token'], nlp)\n",
    "    data['pos'] = linguistic_features['POS']\n",
    "    data['dep'] = linguistic_features['DEP']\n",
    "\n",
    "def prepareDatasetFeatures(data:pd.DataFrame, i:int) -> dict:\n",
    "    \"\"\"Process the features of a token extracted with extractFeatures and\n",
    "    prepares them in the format required by sklearn_crfsuite\n",
    "    Note: this functions takes a lot of time somehow, so it probably needs to be\n",
    "    refactored.\n",
    "\n",
    "    :param data: DataFrame containing the token and their features\n",
    "    :type data: pd.DataFrame\n",
    "    :param i: index of the token\n",
    "    :type i: int\n",
    "    :return: Dictionary where keys are the name of the feature, and values are the features\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    # columns to ignore in DataFrame\n",
    "    ignore_col = ['Id', 'Label']\n",
    "\n",
    "    data = data[[x for x in data.columns if x not in ignore_col]]\n",
    "    # get row associated with this token / index\n",
    "    word_data = data.loc[i]\n",
    "    feature_dict = word_data.to_dict()\n",
    "\n",
    "    # extract features of preceding token (except if the current token is the first)\n",
    "    if i != 0:\n",
    "        prev_word_data = data.loc[i - 1]\n",
    "        for k, v in prev_word_data.to_dict().items():\n",
    "            feature_dict[f\"prev_{k}\"] = v\n",
    "\n",
    "    # extract features of next token (except if the current token is the last)\n",
    "    if i != len(data) - 1:\n",
    "        next_word_data = data.loc[i + 1]\n",
    "        for k, v in next_word_data.to_dict().items():\n",
    "            feature_dict[f\"next_{k}\"] = v\n",
    "\n",
    "    \n",
    "    return feature_dict\n",
    "\n",
    "def gridSearch(param_space:List[tuple]) -> tuple:\n",
    "    \"\"\" I had errors while trying RandomizedSearchCV, so I had to implement something a bit similar\n",
    "\n",
    "    :param param_space: List of tuple containing the combination of parameters to test\n",
    "    :type param_space: List[tuple]\n",
    "    :return: Tuple with the set of parameters reaching the best micro f1 score\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "\n",
    "    # trains models for each possible combination of paramaters\n",
    "    crf_models = []\n",
    "    for param in param_space:\n",
    "        tmp_crf = sklearn_crfsuite.CRF(\n",
    "            # algorithm='lbfgs',\n",
    "            c1=param[0],\n",
    "            c2=param[1],\n",
    "            # max_iterations=500,\n",
    "            # all_possible_transitions=True\n",
    "        )\n",
    "        tmp_crf.fit([X_train], [y_train])\n",
    "        crf_models.append(tmp_crf)\n",
    "\n",
    "    # get the set of parameter with highest micro f1_score\n",
    "    crf_scores = []\n",
    "    for x in crf_models:\n",
    "        y_pred = x.predict([X_dev])\n",
    "        score = f1_score(y_dev, y_pred[0], average='micro')\n",
    "        # score = sklearn_crfsuite.metrics.flat_accuracy_score([y_dev], y_pred)\n",
    "        crf_scores.append(score)\n",
    "\n",
    "    return param_space[np.argmax(crf_scores)]\n",
    "\n",
    "def trainModel(df_train:pd.DataFrame, features_col:List[str], best_param:tuple, savepath:str):\n",
    "\n",
    "    c1 = best_param[0]\n",
    "    c2 = best_param[1]\n",
    "\n",
    "    print('Preparing features...')\n",
    "    X_train = np.array([prepareDatasetFeatures(data=df_train[features_col], i=i) for i in df_train.index])\n",
    "    y_train = df_train['Label'].values\n",
    "\n",
    "    print('Training Model...')\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        c1=c1,\n",
    "        c2=c2,\n",
    "    )\n",
    "    crf.fit([X_train], [y_train])\n",
    "\n",
    "    print('Saving Model...')\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    joblib.dump(crf, f'{savepath}/crf.joblib')\n",
    "\n",
    "    # saving set of features used\n",
    "    with open(f\"{savepath}/params.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"c1\": c1,\n",
    "                \"c2\": c2,\n",
    "                \"features\": list(features_col)\n",
    "            }, f, indent=4\n",
    "        )\n",
    "    print('Done')\n",
    "\n",
    "    return crf\n",
    "\n",
    "def evaluate(df_test:pd.DataFrame, features_col:List[str], crf, savepath:str) -> None : \n",
    "\n",
    "    features_col = [x for x in features_col if x != 'Label']\n",
    "    # makes a deep copy of df_test so as not to modify it\n",
    "    copy_test = df_test.copy(deep=True)\n",
    "    print('Preparing features...')\n",
    "    X = np.array([prepareDatasetFeatures(data=copy_test[features_col], i=i) for i in copy_test.index])\n",
    "\n",
    "    print('Predicting...')\n",
    "    pred = crf.predict([X])\n",
    "    copy_test['Label'] = pred[0]\n",
    "\n",
    "    print('Saving results...')\n",
    "    submission = copy_test[['Id', 'Label']]\n",
    "    submission.to_csv(f'{savepath}/submission.csv', index=False)\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for stopword list and getting token's POS and dependency tags\n",
    "nlp = spacy.load('fr_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# need to clean Token column because each token is surrounded by quotes, which will cause issues later\n",
    "df_train = pd.read_csv('../data/train_2.csv')\n",
    "cleanData(df_train)\n",
    "# update df_train with extracted features\n",
    "extractFeatures(df_train, nlp=nlp)\n",
    "\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "cleanData(df_test)\n",
    "extractFeatures(df_test, nlp=nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with every feature except POS and DEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39857,), (39857,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_col = df_train.columns[:-2]\n",
    "# this might take time to run, since the function is not optimized\n",
    "X_train = np.array([prepareDatasetFeatures(data=df_train[features_col], i=i) for i in df_train.index])\n",
    "y_train = df_train['Label'].values\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Token': '4.5.3',\n",
       " 'lower': '4.5.3',\n",
       " 'isdigit': False,\n",
       " 'isupper': False,\n",
       " 'ispunct': False,\n",
       " 'isstop': False,\n",
       " 'len': 5,\n",
       " 'shape': 'd.d.d',\n",
       " 'prev_Token': '01',\n",
       " 'prev_lower': '01',\n",
       " 'prev_isdigit': True,\n",
       " 'prev_isupper': False,\n",
       " 'prev_ispunct': False,\n",
       " 'prev_isstop': False,\n",
       " 'prev_len': 2,\n",
       " 'prev_shape': 'dd',\n",
       " 'next_Token': '.',\n",
       " 'next_lower': '.',\n",
       " 'next_isdigit': False,\n",
       " 'next_isupper': False,\n",
       " 'next_ispunct': True,\n",
       " 'next_isstop': False,\n",
       " 'next_len': 1,\n",
       " 'next_shape': '.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27899,), (5979,), (27899,), (5979,), (5979,), (5979,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, train_size=.7, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_dev, y_dev, train_size=.5, random_state=42)\n",
    "\n",
    "X_train.shape, X_dev.shape, y_train.shape, y_dev.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: (0.01, 0.1)\n"
     ]
    }
   ],
   "source": [
    "# generates parameters combinations\n",
    "\n",
    "c1 = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "c2 = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "param_space = []\n",
    "\n",
    "for i in range(len(c1)):\n",
    "    for j in range(len(c2)):\n",
    "        param_space.append((c1[i], c2[j]))\n",
    "\n",
    "\n",
    "best_param = gridSearch(param_space)\n",
    "print('Best param:', best_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CRF model with best parameters on whole dataset and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features...\n",
      "Training Model...\n",
      "Saving Model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "savepath = '../models/base_features'\n",
    "base_features_crf = trainModel(df_train, features_col, best_param, savepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test set and generating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Token</th>\n",
       "      <th>lower</th>\n",
       "      <th>isdigit</th>\n",
       "      <th>isupper</th>\n",
       "      <th>ispunct</th>\n",
       "      <th>isstop</th>\n",
       "      <th>len</th>\n",
       "      <th>shape</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>dd</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.1.4.8</td>\n",
       "      <td>2.1.4.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>d.d.d.d</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Conduites</td>\n",
       "      <td>conduites</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>Xxxxxxxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sous-marines</td>\n",
       "      <td>sous-marines</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>xxxx.xxxxxxx</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26168</th>\n",
       "      <td>26168</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>ddd</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26169</th>\n",
       "      <td>26169</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>SYM</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26170</th>\n",
       "      <td>26170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26171</th>\n",
       "      <td>26171</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>ddd</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26172</th>\n",
       "      <td>26172</td>\n",
       "      <td>SAINT-PIERRE-ET-MIQUELON</td>\n",
       "      <td>saint-pierre-et-miquelon</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>XXXXX.XXXXXX.XX.XXXXXXXX</td>\n",
       "      <td>VERB</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26173 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                     Token                     lower  isdigit  \\\n",
       "0          0                        01                        01     True   \n",
       "1          1                   2.1.4.8                   2.1.4.8    False   \n",
       "2          2                         .                         .    False   \n",
       "3          3                 Conduites                 conduites    False   \n",
       "4          4              sous-marines              sous-marines    False   \n",
       "...      ...                       ...                       ...      ...   \n",
       "26168  26168                       103                       103     True   \n",
       "26169  26169                         /                         /    False   \n",
       "26170  26170                         0                         0     True   \n",
       "26171  26171                       103                       103     True   \n",
       "26172  26172  SAINT-PIERRE-ET-MIQUELON  saint-pierre-et-miquelon    False   \n",
       "\n",
       "       isupper  ispunct  isstop  len                     shape    pos     dep  \n",
       "0        False    False   False    2                        dd   NOUN    ROOT  \n",
       "1        False    False   False    7                   d.d.d.d    NUM    nmod  \n",
       "2        False     True   False    1                         .  PUNCT   punct  \n",
       "3        False    False   False    9                 Xxxxxxxxx   NOUN    ROOT  \n",
       "4        False    False   False   12              xxxx.xxxxxxx    ADJ    amod  \n",
       "...        ...      ...     ...  ...                       ...    ...     ...  \n",
       "26168    False    False   False    3                       ddd    NUM  nummod  \n",
       "26169    False     True   False    1                         .    SYM    case  \n",
       "26170    False    False   False    1                         d    NUM  nummod  \n",
       "26171    False    False   False    3                       ddd    NUM    nmod  \n",
       "26172     True    False   False   24  XXXXX.XXXXXX.XX.XXXXXXXX   VERB    amod  \n",
       "\n",
       "[26173 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features...\n",
      "Predicting...\n",
      "Saving results...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "evaluate(df_test, features_col, base_features_crf, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with every feature and POS and without DEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39857,), (39857,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_col = df_train.columns[:-1]\n",
    "# # this might take time to run, since the function is not optimized\n",
    "X_train = np.array([prepareDatasetFeatures(data=df_train[features_col], i=i) for i in df_train.index])\n",
    "y_train = df_train['Label'].values\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27899,), (5979,), (27899,), (5979,), (5979,), (5979,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, train_size=.7, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_dev, y_dev, train_size=.5, random_state=42)\n",
    "\n",
    "X_train.shape, X_dev.shape, y_train.shape, y_dev.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: (0.1, 0.01)\n"
     ]
    }
   ],
   "source": [
    "# generates parameters combinations\n",
    "\n",
    "c1 = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "c2 = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "param_space = []\n",
    "\n",
    "for i in range(len(c1)):\n",
    "    for j in range(len(c2)):\n",
    "        param_space.append((c1[i], c2[j]))\n",
    "\n",
    "\n",
    "best_param = gridSearch(param_space)\n",
    "print('Best param:', best_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CRF model with best parameters on whole dataset and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features...\n",
      "Training Model...\n",
      "Saving Model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "savepath = '../models/features_pos'\n",
    "features_pos_crf = trainModel(df_train, features_col, best_param, savepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test set and generating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features...\n",
      "Predicting...\n",
      "Saving results...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "evaluate(df_test, features_col, features_pos_crf, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with every feature and POS and DEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = df_train.columns\n",
    "# # this might take time to run, since the function is not optimized\n",
    "X_train = np.array([prepareDatasetFeatures(data=df_train[features_col], i=i) for i in df_train.index])\n",
    "y_train = df_train['Label'].values\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27899,), (5979,), (27899,), (5979,), (5979,), (5979,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, train_size=.7, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_dev, y_dev, train_size=.5, random_state=42)\n",
    "\n",
    "X_train.shape, X_dev.shape, y_train.shape, y_dev.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: (0.1, 0.01)\n"
     ]
    }
   ],
   "source": [
    "# generates parameters combinations\n",
    "\n",
    "c1 = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "c2 = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "param_space = []\n",
    "\n",
    "for i in range(len(c1)):\n",
    "    for j in range(len(c2)):\n",
    "        param_space.append((c1[i], c2[j]))\n",
    "\n",
    "\n",
    "best_param = gridSearch(param_space)\n",
    "print('Best param:', best_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CRF model with best parameters on whole dataset and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features...\n",
      "Training Model...\n",
      "Saving Model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "savepath = '../models/features_pos_dep'\n",
    "features_pos_dep_crf = trainModel(df_train, features_col, best_param, savepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test set and generating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features...\n",
      "Predicting...\n",
      "Saving results...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "evaluate(df_test, features_col, features_pos_dep_crf, savepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
